{"runbooks":[{"id":16,"title":"Service Health Check — Full Stack","category":"daily-ops","description":"Daily health check across all services","steps":[{"step":1,"action":"Check all service endpoints","command":"for svc in ptt sip media voice presence auth push cdn pg redis kafka es; do echo -n \"$svc: \"; curl -so /dev/null -w \"%{http_code}\" https://$svc.uc.internal/health; echo; done","expected":"All return 200"},{"step":2,"action":"Check disk usage across fleet","command":"ansible all -m shell -a \"df -h | grep -E '/$|/data'\" | grep -v SUCCESS","expected":"No disk > 80%"},{"step":3,"action":"Verify backup status","command":"aws s3 ls s3://uc-backups/$(date +%Y/%m/%d)/ | wc -l","expected":"Expected backup count present"},{"step":4,"action":"Check certificate expiries","command":"kubectl get certificates -A -o json | jq '.items[] | {name:.metadata.name, expiry:.status.notAfter}'","expected":"No certs expiring within 30 days"}],"severity":"low","estimated_time":"5 min","last_executed":null,"execution_count":180,"created_at":"2026-02-25 03:05:35"},{"id":9,"title":"High Memory — Media Server Recovery","category":"incident-response","description":"Steps to recover from high memory usage on UC Media Server nodes","steps":[{"step":1,"action":"Check current memory usage","command":"ssh media-srv01 \"free -h && top -bn1 | head -20\"","expected":"Identify memory-consuming processes"},{"step":2,"action":"Check transcoding queue depth","command":"curl -s http://media-srv01:9090/metrics | grep transcode_queue","expected":"Queue should be < 100 items"},{"step":3,"action":"Drain transcoding queue","command":"kubectl scale deployment media-transcoder --replicas=0 && sleep 10 && kubectl scale deployment media-transcoder --replicas=3","expected":"Queue drains within 2 minutes"},{"step":4,"action":"Force garbage collection","command":"curl -X POST http://media-srv01:9090/admin/gc","expected":"Memory drops by 20-30%"},{"step":5,"action":"Verify recovery","command":"watch -n5 \"curl -s http://media-srv01:9090/health\"","expected":"Memory < 70%, latency < 100ms"}],"severity":"critical","estimated_time":"10 min","last_executed":null,"execution_count":12,"created_at":"2026-02-25 03:05:35"},{"id":14,"title":"Kafka Consumer Lag Recovery","category":"incident-response","description":"Steps to resolve high consumer lag on Kafka topics","steps":[{"step":1,"action":"Check consumer group lag","command":"kafka-consumer-groups --bootstrap-server kafka:9092 --describe --group ptt-analytics","expected":"Identify lagging partitions"},{"step":2,"action":"Check consumer health","command":"kafka-consumer-groups --bootstrap-server kafka:9092 --describe --group ptt-analytics --state","expected":"All consumers should be active"},{"step":3,"action":"Scale consumers","command":"kubectl scale deployment ptt-analytics-consumer --replicas=6","expected":"More consumers join the group"},{"step":4,"action":"Monitor lag reduction","command":"watch -n10 \"kafka-consumer-groups --bootstrap-server kafka:9092 --describe --group ptt-analytics 2>/dev/null | tail -5\"","expected":"Lag should decrease steadily"}],"severity":"medium","estimated_time":"10 min","last_executed":null,"execution_count":4,"created_at":"2026-02-25 03:05:35"},{"id":10,"title":"Redis Session Store — Eviction Mitigation","category":"incident-response","description":"Handle elevated eviction rates on Redis session store","steps":[{"step":1,"action":"Check memory stats","command":"redis-cli -h redis-session INFO memory","expected":"Identify used_memory vs maxmemory"},{"step":2,"action":"Identify large keys","command":"redis-cli -h redis-session --bigkeys","expected":"Find keys consuming disproportionate memory"},{"step":3,"action":"Check TTL distribution","command":"redis-cli -h redis-session DEBUG OBJECT $(redis-cli -h redis-session RANDOMKEY)","expected":"Verify TTLs are set correctly"},{"step":4,"action":"Purge expired sessions manually","command":"redis-cli -h redis-session SCAN 0 MATCH \"ptt:session:*\" COUNT 1000","expected":"Remove sessions with no TTL"},{"step":5,"action":"Increase maxmemory if needed","command":"redis-cli -h redis-session CONFIG SET maxmemory 6gb","expected":"Evictions should stop immediately"}],"severity":"high","estimated_time":"15 min","last_executed":null,"execution_count":8,"created_at":"2026-02-25 03:05:35"},{"id":15,"title":"CDN Cache Purge & Warm","category":"maintenance","description":"Purge stale CDN cache and warm critical paths","steps":[{"step":1,"action":"Purge cache by tag","command":"curl -X POST https://cdn-api.internal/purge -d '{\"tag\":\"config-v2\"}'","expected":"Purge accepted, propagation < 2min"},{"step":2,"action":"Verify purge propagation","command":"for edge in edge-{us,eu,ap}; do curl -sI https://$edge.cdn.internal/config.json | grep \"x-cache\"; done","expected":"All edges return MISS"},{"step":3,"action":"Warm critical paths","command":"cat critical-urls.txt | xargs -P10 -I{} curl -so /dev/null {}","expected":"All URLs cached again"}],"severity":"low","estimated_time":"5 min","last_executed":null,"execution_count":20,"created_at":"2026-02-25 03:05:35"},{"id":12,"title":"TLS Certificate Renewal","category":"maintenance","description":"Renew TLS certificates using ACME/Let's Encrypt","steps":[{"step":1,"action":"Check current certificate expiry","command":"echo | openssl s_client -connect auth.uc.internal:443 2>/dev/null | openssl x509 -noout -dates","expected":"Identify expiry date"},{"step":2,"action":"Verify DNS challenge records","command":"dig TXT _acme-challenge.auth.uc.internal +short","expected":"Challenge record should exist"},{"step":3,"action":"Trigger manual renewal","command":"certbot renew --cert-name auth.uc.internal --force-renewal","expected":"Certificate renewed successfully"},{"step":4,"action":"Reload TLS config","command":"nginx -t && systemctl reload nginx","expected":"Nginx config valid, reload successful"},{"step":5,"action":"Verify new certificate","command":"curl -vI https://auth.uc.internal 2>&1 | grep -E \"expire|subject\"","expected":"New expiry date > 60 days out"}],"severity":"medium","estimated_time":"10 min","last_executed":null,"execution_count":15,"created_at":"2026-02-25 03:05:35"},{"id":13,"title":"Database Replication Lag Troubleshooting","category":"troubleshooting","description":"Diagnose and resolve PostgreSQL replication lag issues","steps":[{"step":1,"action":"Check replication status","command":"psql -h pg-primary -c \"SELECT client_addr, state, sent_lsn, write_lsn, replay_lsn, replay_lag FROM pg_stat_replication;\"","expected":"Identify lagging replicas"},{"step":2,"action":"Check WAL generation rate","command":"psql -h pg-primary -c \"SELECT pg_current_wal_lsn(), pg_wal_lsn_diff(pg_current_wal_lsn(), replay_lsn) as lag_bytes FROM pg_stat_replication;\"","expected":"Lag bytes should be < 100MB"},{"step":3,"action":"Identify long-running queries on replica","command":"psql -h pg-replica -c \"SELECT pid, now() - query_start AS duration, query FROM pg_stat_activity WHERE state != 'idle' ORDER BY duration DESC LIMIT 10;\"","expected":"No queries running > 60s"},{"step":4,"action":"Check for conflicting queries","command":"psql -h pg-replica -c \"SELECT * FROM pg_stat_database_conflicts WHERE datname = 'ucdb';\"","expected":"Minimal conflicts"}],"severity":"medium","estimated_time":"15 min","last_executed":null,"execution_count":6,"created_at":"2026-02-25 03:05:35"},{"id":11,"title":"SIP Proxy — 503 Error Investigation","category":"troubleshooting","description":"Diagnose and resolve SIP 503 Service Unavailable errors","steps":[{"step":1,"action":"Check SIP proxy health","command":"curl -I https://sip-proxy.uc.internal/health","expected":"HTTP 200 with healthy status"},{"step":2,"action":"Check connection pool","command":"ss -s && ss -tnp | grep \":5060\" | wc -l","expected":"Active connections < pool limit"},{"step":3,"action":"Review error logs","command":"journalctl -u sip-proxy --since \"1 hour ago\" | grep \"503\\|error\\|timeout\"","expected":"Identify root cause pattern"},{"step":4,"action":"Test upstream connectivity","command":"for host in backend-{1..4}; do curl -w \"%{time_total}\\n\" -o /dev/null -s http://$host:8080/health; done","expected":"All backends respond < 500ms"},{"step":5,"action":"Restart affected pods if needed","command":"kubectl rollout restart deployment sip-proxy -n uc-prod","expected":"New pods come up healthy"}],"severity":"high","estimated_time":"20 min","last_executed":null,"execution_count":5,"created_at":"2026-02-25 03:05:35"}],"categories":["daily-ops","incident-response","maintenance","troubleshooting"]}